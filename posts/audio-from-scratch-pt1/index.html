<!DOCTYPE html>
<html lang="en-us">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.73.0" />

    
    
    

<title>Audio From Scratch: Part 1, generating sounds ‚Ä¢ Dylan Meeus</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Audio From Scratch: Part 1, generating sounds"/>
<meta name="twitter:description" content="Audio from scratch: generating sound In my &lsquo;audio from scratch&rsquo; series we will take a look at various ways in which we can manipulate audio data with Go. We&rsquo;ll look at the anatomy of a wave file, how to apply stereo panning, converting mono files to stereo, how to work with breakpoint files through linear interpolation, etc.
But, in this post we‚Äôll be using Go to create sound from scratch in binary format."/>

<meta property="og:title" content="Audio From Scratch: Part 1, generating sounds" />
<meta property="og:description" content="Audio from scratch: generating sound In my &lsquo;audio from scratch&rsquo; series we will take a look at various ways in which we can manipulate audio data with Go. We&rsquo;ll look at the anatomy of a wave file, how to apply stereo panning, converting mono files to stereo, how to work with breakpoint files through linear interpolation, etc.
But, in this post we‚Äôll be using Go to create sound from scratch in binary format." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://dylanmeeus.github.io/posts/audio-from-scratch-pt1/" />
<meta property="article:published_time" content="2020-07-13T18:43:21+02:00" />
<meta property="article:modified_time" content="2020-07-13T18:43:21+02:00" />


    






<link rel="stylesheet" href="/scss/hyde-hyde.6a83d62c39a364f036df4db1ecd564645635d6c7fc182425cb501218fec485f5.css" integrity="sha256-aoPWLDmjZPA2302x7NVkZFY11sf8GCQly1ASGP7EhfU=">


<link rel="stylesheet" href="/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">




    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-172416417-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-172416417-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    
    

</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://dylanmeeus.github.io">Dylan Meeus</a>
      </span>
      
      
        <div class="author-image">
          <img src="https://www.gravatar.com/avatar/174fdce3b3920fc7b21aff714b0b664d?s=240&d=mp" class="img--circle img--headshot element--center" alt="gravatar">
        </div>
      
      <p class="site__description">
        
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Dylan Meeus</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		
	</ul>
</div>

        <section class="social">
	
	<a href="https://twitter.com/DylanMeeus" rel="me"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	<a href="https://github.com/DylanMeeus" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	<a href="https://linkedin.com/in/dylanmeeus" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	
</section>

      </div>
    </div>
    


  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>Audio From Scratch: Part 1, generating sounds</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Jul 13, 2020
    
    
    
      
      
          in
          
          
              <a class="badge badge-category" href="/categories/posts">POSTS</a>
              
          
      
    
    
    
      
      
          <br/>
           <i class="fas fa-tags"></i>
          
          <a class="badge badge-tag" href="/tags/posts">posts</a>
          
      
    
    
    <br/>
    <i class="fas fa-clock"></i> 6 min read
</div>


  </header>
  
  
  <div class="post">
    <h1 id="audio-from-scratch-generating-sound">Audio from scratch: generating sound</h1>
<p>In my &lsquo;audio from scratch&rsquo; series we will take a look at various ways in which we can manipulate
audio data with Go. We&rsquo;ll look at the anatomy of a wave file, how to apply stereo panning,
converting mono files to stereo, how to work with breakpoint files through linear interpolation,
etc.</p>
<p>But, in this post we‚Äôll be using Go to create sound from scratch in binary format. The end result of this post is to play a sound of a certain frequency, sample rate and duration. We‚Äôll also apply an exponential decay so the sound will taper off. In the end, the sound should become the one from this video:</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://player.vimeo.com/video/435405664" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="vimeo video" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
 </div>

<h1 id="step-1-what-the-sound">Step 1: What the sound?</h1>
<p>In it‚Äôs most simple form, sound to a computer can be thought of as a simple wave encoded digitally. Before the sound reaches your ears it goes through a digital to analog converter, essentially translating the digital signal to a current for your headphones / speakers.
For example, note A would look like this:</p>
<p><img src="http://www-users.math.umn.edu/~rogness/math1155/soundwaves/a.png" alt="">
(source: <a href="http://www-users.math.umn.edu/~rogness/math1155/soundwaves/">http://www-users.math.umn.edu/~rogness/math1155/soundwaves/</a>)</p>
<p>As a first step, let‚Äôs try to just create a sine wave with go.
We can generate this using math.Sin(x) and pass x as radians. We‚Äôll have to iterate over a range to get the sine wave out of this. To stay in the realm of audio programming, the amount of ‚Äòpoints‚Äô that we‚Äôll plot to the sine wave are our samples.
(If you want to skip ahead, all code for this post is on github: <a href="https://github.com/DylanMeeus/MediumCode/blob/master/Audio">https://github.com/DylanMeeus/MediumCode/blob/master/Audio</a>)</p>
<pre><code>const nsamps = 50 // samples to generate
func generate() {
     tau = math.Pi * 2
     var angle float64 = tau / nsamps
     for i := 0; i &lt; nsamps; i++ {
         samp = math.Sin(angle * float64(i))
         fmt.Printf(&quot;%.8f\n&quot;, samp)
     }
}
</code></pre><p>Notice that we print the sample to stdout, we can pipe this output to a file (go run main.go &gt; out.txt) . The output in this file will look like this:</p>
<pre><code>-0.00000000
-0.12533323
-0.24868989
-0.36812455
-0.48175367
-0.58778525
</code></pre><p>..
Kind of hard to see what‚Äôs going on here. But using gnuplot we can visualize this file easier. In gnuplot, run:</p>
<p><code>plot &quot;out.txt&quot; with lines</code></p>
<p><img src="https://miro.medium.com/max/640/1*kL8CAzHZxYOrMBkvDFOMfA.png" alt=""></p>
<p>This looks like a perfectly continuous sine-wave, but that‚Äôs the way gnuplot is visualizing it ‚Äúwith lines‚Äù. If we plot the bars we can see a slightly different view. ( plot &ldquo;out.txt&rdquo; with boxes )</p>
<p><img src="https://miro.medium.com/max/640/1*BOs1Fyln54FvmJnKBkh2Fw.png" alt=""></p>
<p>Now that we can generate sine-waves, we have the basics of how we can make sound. Although this is just floating point numbers at this point, we can actually turn this into something playable as a raw audio file.</p>
<h1 id="step-2-generating-sound">Step 2: Generating sound</h1>
<p>To turn this sine wave into an actual sound we‚Äôll have to introduce a few things.</p>
<h2 id="sample-rates"><strong>Sample Rates</strong></h2>
<p>Firstly, sound is stored at a certain sample rate. A sample rate tells you how many samples per second are used to encode your sound. A CD-Quality recording has a sample rate of 44100 hertz, allowing for a frequency of up to 22.05KHz. Considering the human ear hears sound between 20Hz to 20KHz, this is plenty (Assuming you‚Äôre only targetting human listeners üòõ).
Although other formats are possible, such as 48Khz for DVD-Video quality or 96KHz for DVD-Audio quality, we‚Äôll stick with CD-Quality for now. As you will see ‚Äî changing this would be trivial however. Feel free to play around with this yourself to see if you can hear a difference in sound.
So instead of using our nsamps = 50 we‚Äôll need at least 44100 samples. To adjust the duration of the sound we‚Äôll also add a variable for this.</p>
<pre><code>const (
      Duration = 2
      SampleRate = 44100
)
</code></pre><h2 id="frequency"><strong>Frequency</strong></h2>
<p>Next, we‚Äôll introduce a frequency. For now we will use a frequency of 440Hz which is defined as the ‚Äúpitch standard‚Äù. It‚Äôs the standard tuning of musical note A above middle C. To not diverge to much of our goal to generate music, just check this wiki page if you‚Äôre curious as to why we are using this frequency.
Adding this we‚Äôll expand our consts again:</p>
<pre><code>const (
      Duration   = 2
      SampleRate = 44100
      Frequency  = 440  // Pitch Standard
)
</code></pre><h2 id="storing-sound"><strong>Storing sound</strong></h2>
<p>We now have the basic ingredients for generating sound, but we miss one vital part. How can we store this data so our computer can interpret it as sound?
Our floats that we generated in step 1 can indeed be used, but we will have to store them as a binary representation. One tricky part here is that you have to store them in a way your computer can read them ‚Äî meaning you‚Äôll have to use BigEndian on a BigEndian machine or LittleEndian otherwise.
On a linux system this can be discovered through your terminal (possibly same command on macOS, don‚Äôt have one to verify!).</p>
<pre><code>dylan@devuan:~$ lscpu | grep &quot;Byte Order&quot;
Byte Order:            Little Endian
</code></pre><h2 id="the-code"><strong>The Code!</strong></h2>
<p>Now we know what to do, and have our constants set up, let‚Äôs revise the generate function to tie it all together. The sound will be stored in a file called ‚Äúout.bin‚Äù on your machine. (For brevity, I have removed error handling!)</p>
<pre><code>func generate() {
	nsamps := Duration * SampleRate
	var angle float64 = tau / float64(nsamps)
	file := &quot;out.bin&quot;
	f, _ := os.Create(file)
	for i := 0; i &lt; nsamps; i++ {
		sample := math.Sin(angle * Frequency * float64(i))
		var buf [8]byte
		binary.LittleEndian.PutUint32(buf[:],
                       math.Float32bits(float32(sample)))
		bw,_ := f.Write(buf[:])
		fmt.Printf(&quot;\rWrote: %v bytes to %s&quot;, bw, file)
	}
}
</code></pre><p>Using ffplay we can now play this file, although we will need to specify our sample rate and our format. Specifying our showmode we can also visualize the sound being played:</p>
<pre><code>ffplay -f f32le -ar  44100 -showmode 1 out.bin
</code></pre><p><img src="https://miro.medium.com/max/640/1*BbaovxPpS_HmMsBlNIPdgQ.png" alt=""></p>
<p>playing our file using ffplay
It sounds like this:</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://player.vimeo.com/video/435468028" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="vimeo video" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
 </div>

<p>Alternatively you could also use Audacity and import our binary file as a ‚Äòraw audio file‚Äô. Just make sure you select mono channel and the correct encoding. üòâ
This is how we could create the pitch standard. Although a small improvement would be to tamper the sound near the end. That would feel more ‚Äònatural‚Äô than having a constant signal. To achieve this we can introduce exponential decay near the end of the signal.
Extension 1: Exponential Decay
We don‚Äôt have to add a lot to get the exponential decay. We want to fade out our signal so we‚Äôll define a start and an end ‚Äòamplitude‚Äô to generate a decay factor. Next on each iteration we‚Äôll modify our signal‚Äôs actual amplitude by multiplying it with a decay factor.
At the top of our function, we‚Äôll define these variables:</p>
<pre><code>func generate() {
     var (
         start float64 = 1.0
         end float64   = 1.0e-4
     )
     nsamps = Duration * SampleRate
     decayfac := math.Pow(end/start, 1.0/float64(nsamps))
     ..
</code></pre><p>Once we have them set up, in our loop for generating the wave we can just modify the sample on each iteration</p>
<pre><code>sample := math.Sin(angle * Frequency * float64(i))
sample *= start
start *= decayfac
</code></pre><p>When we put this together, our function becomes:</p>
<pre><code>func generate() {
	var (
		start float64 = 1.0
		end   float64 = 1.0e-4
	)
	nsamps := Duration * SampleRate
	var angle float64 = tau / float64(nsamps)
	file := &quot;out.bin&quot;
	f, _ := os.Create(file)
	decayfac := math.Pow(end/start, 1.0/float64(nsamps))
	for i := 0; i &lt; nsamps; i++ {
		sample := math.Sin(angle * Frequency * float64(i))
		sample *= start
		start *= decayfac
		var buf [8]byte
		binary.LittleEndian.PutUint32(buf[:],
                       math.Float32bits(float32(sample)))
		bw, _ := f.Write(buf[:])
		fmt.Printf(&quot;\rWrote: %v bytes to %s&quot;, bw, file)
	}
}
</code></pre><p>And now if we play this sound, we get the sound from the video at the top of this post. üòÉ
All code is on GitHub: <a href="https://github.com/DylanMeeus/MediumCode/blob/master/Audio/FirstSound/main.go">https://github.com/DylanMeeus/MediumCode/blob/master/Audio/FirstSound/main.go</a></p>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="/posts/hasgo/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Hasgo: how does it work?</span>
    </a>
    
    
</div>


  

  
    


</article>


        </div>
        
    

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-172416417-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script defer src="https://use.fontawesome.com/releases/v5.11.2/js/all.js" integrity="sha384-b3ua1l97aVGAPEIe48b4TC60WUQbQaGi2jqAWM90y0OZXZeyaTCWtBTKtjW2GXG1" crossorigin="anonymous"></script>




    



    </body>
</html>
